{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we train Word2Vec on AGNews text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\86183\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90000, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wall st. bears claw back into the black (reute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>carlyle looks toward commercial aerospace (reu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oil and economy cloud stocks' outlook (reuters...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iraq halts oil exports from main southern pipe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oil prices soar to all-time record, posing new...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  wall st. bears claw back into the black (reute...\n",
       "1  carlyle looks toward commercial aerospace (reu...\n",
       "2  oil and economy cloud stocks' outlook (reuters...\n",
       "3  iraq halts oil exports from main southern pipe...\n",
       "4  oil prices soar to all-time record, posing new..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ag = pd.read_csv(\"../HomeWork1/ag.csv\")\n",
    "print(ag.shape)\n",
    "ag.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec<vocab=25389, vector_size=100, alpha=0.025>\n",
      "[-1.0185182   1.0597867  -0.5869825   2.1043217  -0.32311937  0.7042859\n",
      "  1.0434008  -1.2307667   1.6345253  -0.8659341   0.30565715  0.79652405\n",
      "  1.0993587  -0.7523909  -2.159914    0.85680795 -0.0672893   1.5678796\n",
      "  1.3625771  -0.4529641   1.1533221   0.7091411   0.7207622   0.13700038\n",
      "  0.22972478  0.32556632 -1.4616694   1.3461691  -0.6263655   1.9706436\n",
      "  1.074446   -0.18022203 -0.30738994 -0.43006128  0.22188076 -0.22365646\n",
      "  0.1891554   0.81460845  0.12415149  1.7362758   0.0152154  -0.12946442\n",
      " -0.59924644  0.7598288  -0.4991222   0.97637343 -1.7476748  -0.6420553\n",
      " -0.6739624  -0.3259385  -0.17657325 -1.0000002  -1.2420468   0.8297787\n",
      "  0.09147941  1.4425206  -0.58668214  0.61572415 -2.1666646  -0.1067452\n",
      " -0.47582078  0.7702358  -0.17053765 -1.8544205   2.0656345   1.1561612\n",
      "  2.6926045   0.74130136  1.8225517   1.5557338  -0.88574797 -2.1144047\n",
      " -0.2084011   2.2124333   0.403437   -0.874645    0.6349529  -0.63600904\n",
      "  0.36604974  0.41131252  0.8177888   1.8633093   1.7582034  -1.4029336\n",
      "  0.45594388 -0.8685486   1.3740801   0.0734441  -0.13332376 -0.911928\n",
      " -0.11575808  0.71563876  0.83756655 -1.3799925   0.2821565  -0.23924193\n",
      " -1.1351668  -0.4581537  -0.23623823  0.653671  ]\n"
     ]
    }
   ],
   "source": [
    "sentences = [word_tokenize(text) for text in ag[\"text\"].to_list()]\n",
    "word2vec_model = Word2Vec(sentences=sentences, vector_size=100, workers=4)\n",
    "print(word2vec_model)\n",
    "print(word2vec_model.wv[\"the\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.50715053e-01  7.26831496e-01  2.08814610e-02  2.93653667e-01\n",
      " -1.62549078e-01 -2.08014667e-01  2.83165038e-01 -3.34622294e-01\n",
      "  7.21142292e-01 -1.38007373e-01  4.31619704e-01 -3.42079908e-01\n",
      "  4.16156083e-01 -4.75730211e-01 -9.04971838e-01 -2.41975524e-02\n",
      "  2.08167404e-01  3.05923730e-01  3.20417225e-01 -3.48953992e-01\n",
      "  5.94729066e-01  1.01348072e-01  2.42377728e-01 -1.10951923e-02\n",
      " -1.35424674e-01  3.08533877e-01 -1.89357042e-01  4.02220935e-01\n",
      "  1.97609831e-02  2.81636745e-01  3.65686208e-01 -1.54718459e-01\n",
      " -2.10146829e-01 -5.04583895e-01 -6.54898211e-02  3.53946686e-01\n",
      "  1.90306738e-01  5.22515297e-01 -7.29097426e-02  3.98994118e-01\n",
      " -1.51943974e-02  1.83699563e-01 -2.95269519e-01  9.48270597e-03\n",
      "  1.82910413e-01 -2.44965866e-01 -8.83262277e-01 -5.85051537e-01\n",
      " -2.57507801e-01 -3.11714143e-01 -3.59205991e-01 -2.97075927e-01\n",
      " -1.66084319e-01  4.74583685e-01  3.07300270e-01  6.09182239e-01\n",
      " -3.00029427e-01  1.16512865e-01 -6.37081981e-01  8.87649506e-02\n",
      " -3.05698425e-01 -1.41662449e-01 -1.62455127e-01 -1.67912155e-01\n",
      " -6.08433445e-04  4.28352624e-01  8.32991078e-02  3.03069651e-01\n",
      "  8.71996701e-01  6.16695881e-01 -1.62629128e-01  1.49304211e-01\n",
      "  6.09573781e-01  4.61726665e-01  5.36965311e-01 -1.75363719e-01\n",
      "  2.60909438e-01 -1.94275677e-01  4.50849593e-01  3.21109682e-01\n",
      "  1.73690170e-01  4.16311085e-01 -4.58085723e-02  1.30014434e-01\n",
      "  1.76869467e-01 -2.47203618e-01  5.54233849e-01  2.57646620e-01\n",
      " -5.61224967e-02 -3.45148653e-01 -2.59752646e-02  3.29686731e-01\n",
      "  6.69725180e-01 -4.24136370e-01  3.92774910e-01 -1.25309844e-02\n",
      " -2.48153582e-01 -3.00931424e-01  5.99825792e-02 -1.07685462e-01]\n"
     ]
    }
   ],
   "source": [
    "def get_text_vector(text, model=word2vec_model):\n",
    "    words = word_tokenize(text.lower())\n",
    "    word_vectors = []\n",
    "    for word in words:\n",
    "        if word.lower() in model.wv.key_to_index:\n",
    "            word_vectors.append(model.wv[word.lower()])\n",
    "        else:\n",
    "            continue\n",
    "    return np.mean(word_vectors, axis=0)\n",
    "\n",
    "example_output = get_text_vector(text=\"The quick brown fox jumps over the lazy dog\")\n",
    "print(example_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11519, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(reuters) - carlos tevez sealed his move to ju...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>if professional pride and strong defiance can ...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>palermo, sicily â€” roberta vinci beat top-seede...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spain's big two soccer teams face a pair of it...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the argentine soccer club san lorenzo complete...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   label\n",
       "0  (reuters) - carlos tevez sealed his move to ju...  sports\n",
       "1  if professional pride and strong defiance can ...  sports\n",
       "2  palermo, sicily â€” roberta vinci beat top-seede...  sports\n",
       "3  spain's big two soccer teams face a pair of it...  sports\n",
       "4  the argentine soccer club san lorenzo complete...  sports"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../HomeWork1/nyt.csv\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df(df, train_size=0.8, val_size=0.1, test_size=0.1, random_state=42):\n",
    "    train_df, temp_df = train_test_split(df, test_size=(1 - train_size), random_state=random_state)\n",
    "    val_df, test_df = train_test_split(temp_df, test_size=test_size / (val_size + test_size), random_state=random_state)\n",
    "    return train_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9215, 2) (1152, 2) (1152, 2)\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df, test_df = split_df(df)\n",
    "print(train_df.shape, val_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9215/9215 [00:51<00:00, 180.64it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1152/1152 [00:05<00:00, 200.93it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1152/1152 [00:05<00:00, 198.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9215, 100) (1152, 100) (1152, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array([get_text_vector(text) for text in tqdm(train_df[\"text\"].to_list(), total=len(train_df))])\n",
    "X_val = np.array([get_text_vector(text) for text in tqdm(val_df[\"text\"].to_list(), total=len(val_df))])\n",
    "X_test = np.array([get_text_vector(text) for text in tqdm(test_df[\"text\"].to_list(), total=len(test_df))])\n",
    "print(X_train.shape, X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=2000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=2000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=2000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=2000)\n",
    "model.fit(X_train, train_df[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results on the validation set are:\n",
      "Accuracy Score: 0.9730902777777778\n",
      "Macro F1-Score: 0.9352031637469408\n",
      "Micro F1-Score: 0.9730902777777778\n"
     ]
    }
   ],
   "source": [
    "val_preds = model.predict(X_val)\n",
    "accuracy = accuracy_score(val_df[\"label\"], val_preds)\n",
    "macro_f1 = f1_score(val_df[\"label\"], val_preds, average=\"macro\")\n",
    "micro_f1 = f1_score(val_df[\"label\"], val_preds, average=\"micro\")\n",
    "\n",
    "print(\"The results on the validation set are:\")\n",
    "print(f\"Accuracy Score: {accuracy}\")\n",
    "print(f\"Macro F1-Score: {macro_f1}\")\n",
    "print(f\"Micro F1-Score: {micro_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results on the test set are:\n",
      "Accuracy Score: 0.9713541666666666\n",
      "Macro F1-Score: 0.9288212871380201\n",
      "Micro F1-Score: 0.9713541666666666\n"
     ]
    }
   ],
   "source": [
    "test_preds = model.predict(X_test)\n",
    "accuracy = accuracy_score(test_df[\"label\"], test_preds)\n",
    "macro_f1 = f1_score(test_df[\"label\"], test_preds, average=\"macro\")\n",
    "micro_f1 = f1_score(test_df[\"label\"], test_preds, average=\"micro\")\n",
    "\n",
    "print(\"The results on the test set are:\")\n",
    "print(f\"Accuracy Score: {accuracy}\")\n",
    "print(f\"Macro F1-Score: {macro_f1}\")\n",
    "print(f\"Micro F1-Score: {micro_f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
