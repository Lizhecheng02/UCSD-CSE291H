{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This code is based on my previous written code [here](https://www.kaggle.com/code/lizhecheng/96-accuracy-bert-model-nlp-classification). However, that code contains many errors and I have fixed all of them in this ``ipynb`` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "import spacy\n",
    "import nltk \n",
    "import string\n",
    "import regex as re \n",
    "import warnings\n",
    "from torch import nn\n",
    "from sklearn.metrics import f1_score\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from tqdm import tqdm\n",
    "from transformers import logging\n",
    "logging.set_verbosity_warning()\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, device(type='cuda'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we use a single A100 GPU to do the training\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "use_cuda, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11519, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(reuters) - carlos tevez sealed his move to ju...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>if professional pride and strong defiance can ...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>palermo, sicily — roberta vinci beat top-seede...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spain's big two soccer teams face a pair of it...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the argentine soccer club san lorenzo complete...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   label\n",
       "0  (reuters) - carlos tevez sealed his move to ju...  sports\n",
       "1  if professional pride and strong defiance can ...  sports\n",
       "2  palermo, sicily — roberta vinci beat top-seede...  sports\n",
       "3  spain's big two soccer teams face a pair of it...  sports\n",
       "4  the argentine soccer club san lorenzo complete...  sports"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../HomeWork1/nyt.csv\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5, 3))\n",
    "df[\"label\"].value_counts().plot(kind=\"barh\", color=\"green\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_number(label):\n",
    "    mapping = {\"business\": 0, \"politics\": 1, \"sports\": 2}\n",
    "    return mapping.get(label, -1)\n",
    "\n",
    "df[\"label\"] = df[\"label\"].apply(label_to_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.12.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.8.2)\n",
      "Requirement already satisfied: jinja2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (72.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.7.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.7.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.18.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.0)\n",
      "Requirement already satisfied: wrapt in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.7.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to /home/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package punkt_tab to /home/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm\n",
    "sp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"punkt_tab\")\n",
    "\n",
    "nltk_st = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text, http=True, punc=True, lem=True, stop_w=True):\n",
    "    if http == True:\n",
    "        text = re.sub(\"https?:\\/\\/t.co\\/[A-Za-z0-9]*\", \"\", text)\n",
    "    if stop_w == True:\n",
    "        text = [word for word in word_tokenize(text) if not word.lower() in nltk_st]\n",
    "        text = \" \".join(text)\n",
    "    if lem == True:\n",
    "        lemmatized = [word.lemma_ for word in sp(text)]\n",
    "        text = \" \".join(lemmatized)\n",
    "    if punc == True:\n",
    "        text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "        \n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"what's\", \"what is\", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"can't\", \"cannot\", text)\n",
    "    text = re.sub(r\"n't\", \" not\", text)\n",
    "    text = re.sub(r\"i'm\", \"i am\", text)\n",
    "    text = re.sub(r\"im\", \"i am\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'scuse\", \" excuse\", text)\n",
    "    text = re.sub(\"\\W\", \" \", text)\n",
    "    text = re.sub(\"\\s+\", \" \", text)\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 μs, sys: 1 μs, total: 3 μs\n",
      "Wall time: 4.53 μs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>reuters carlos tevez sealed his move to juvent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>if professional pride and strong defiance can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>palermo sicily roberta vinci beat top seeded f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>spain big two soccer teams face a pair of ital...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>the argentine soccer club san lorenzo complete...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                       cleaned_text\n",
       "0      2  reuters carlos tevez sealed his move to juvent...\n",
       "1      2  if professional pride and strong defiance can ...\n",
       "2      2  palermo sicily roberta vinci beat top seeded f...\n",
       "3      2  spain big two soccer teams face a pair of ital...\n",
       "4      2  the argentine soccer club san lorenzo complete..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "DO_PREPROCESS = True\n",
    "if DO_PREPROCESS:\n",
    "    df[\"cleaned_text\"] = df[\"text\"].apply(lambda text: clean(text, http=True, punc=False, lem=False, stop_w=False))\n",
    "else:\n",
    "    df[\"cleaned_text\"] = df[\"text\"]\n",
    "df.drop(columns=[\"text\"], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08ed6929503644c1a4ab53a69f92260b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1208b1c1777c4208b54e6137ba5be3b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17cd0569824d4ff183fa040bee5b3be6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf9d9bda634a48b78a12e5c8d349595e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9215 1152 1152\n"
     ]
    }
   ],
   "source": [
    "PRE_TRAINED_MODEL_NAME = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "\n",
    "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42), [int(0.8 * len(df)), int(0.9 * len(df))])\n",
    "print(len(df_train), len(df_val), len(df_test))\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length=64):\n",
    "        self.labels = df[\"label\"].to_list()\n",
    "        self.texts = df[\"cleaned_text\"].to_list()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].flatten(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].flatten(),\n",
    "            \"label\": torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaf4ceb3c6fc435f8314953167faa815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertClassifier(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSdpaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (linear): Linear(in_features=768, out_features=3, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self, dropout=0.5, num_classes=3):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        pooler_output = self.bert(input_ids=input_ids, attention_mask=attention_mask).pooler_output\n",
    "        dropout_output = self.dropout(pooler_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "        return final_layer\n",
    "    \n",
    "model = BertClassifier()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_data, val_data, learning_rate=2e-6, epochs=3, T_max=3):\n",
    "    train = Dataset(df=train_data, tokenizer=tokenizer)\n",
    "    val = Dataset(df=val_data, tokenizer=tokenizer)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=16, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=16)\n",
    "\n",
    "    class_weights = torch.tensor([2.0, 2.0, 1.0], dtype=torch.float32)\n",
    "    criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=T_max)\n",
    "\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "\n",
    "    for epoch_num in range(epochs):\n",
    "        total_acc_train = 0\n",
    "        total_loss_train = 0\n",
    "        for train_batch in tqdm(train_dataloader, total=len(train_dataloader), desc=f\"Training Epoch: {epoch_num + 1}\"):\n",
    "            input_ids = train_batch[\"input_ids\"].to(device)\n",
    "            attention_mask = train_batch[\"attention_mask\"].to(device)\n",
    "            train_labels = train_batch[\"label\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            batch_loss = criterion(outputs, train_labels)\n",
    "            total_loss_train += batch_loss.item()\n",
    "            \n",
    "            acc = (outputs.argmax(dim=1) == train_labels).sum().item()\n",
    "            total_acc_train += acc\n",
    "\n",
    "            model.zero_grad()\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "        \n",
    "        total_acc_val = 0\n",
    "        total_loss_val = 0\n",
    "        with torch.no_grad():\n",
    "            for val_batch in tqdm(val_dataloader, total=len(val_dataloader), desc=f\"Validating Epoch: {epoch_num + 1}\"):\n",
    "                input_ids = val_batch[\"input_ids\"].to(device)\n",
    "                attention_mask = val_batch[\"attention_mask\"].to(device)\n",
    "                val_labels = val_batch[\"label\"].to(device)\n",
    "\n",
    "                outputs = model(input_ids, attention_mask)\n",
    "                batch_loss = criterion(outputs, val_labels)\n",
    "                total_loss_val += batch_loss.item()\n",
    "                \n",
    "                acc = (outputs.argmax(dim=1) == val_labels).sum().item()\n",
    "                total_acc_val += acc\n",
    "        \n",
    "        print(f\"Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_dataloader): .3f} | Train Accuracy: {total_acc_train / len(train_data): .3f} | Val Loss: {total_loss_val / len(val_dataloader): .3f} | Val Accuracy: {total_acc_val / len(val_data): .3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch: 1: 100%|██████████| 576/576 [01:36<00:00,  5.99it/s]\n",
      "Validating Epoch: 1: 100%|██████████| 72/72 [00:10<00:00,  7.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  0.597 | Train Accuracy:  0.820 | Val Loss:  0.365 | Val Accuracy:  0.908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch: 2: 100%|██████████| 576/576 [01:32<00:00,  6.20it/s]\n",
      "Validating Epoch: 2: 100%|██████████| 72/72 [00:10<00:00,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss:  0.271 | Train Accuracy:  0.939 | Val Loss:  0.171 | Val Accuracy:  0.974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch: 3: 100%|██████████| 576/576 [01:33<00:00,  6.19it/s]\n",
      "Validating Epoch: 3: 100%|██████████| 72/72 [00:10<00:00,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 | Train Loss:  0.146 | Train Accuracy:  0.975 | Val Loss:  0.141 | Val Accuracy:  0.976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(model, df_train, df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_data):\n",
    "    test = Dataset(df=test_data, tokenizer=tokenizer)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=16)\n",
    "\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    total_acc_test = 0\n",
    "    with torch.no_grad():\n",
    "        for test_batch in tqdm(test_dataloader, total=len(test_dataloader), desc=\"Testing\"):\n",
    "            input_ids = test_batch[\"input_ids\"].to(device)\n",
    "            attention_mask = test_batch[\"attention_mask\"].to(device)\n",
    "            labels = test_batch[\"label\"].to(device)\n",
    "\n",
    "            output = model(input_ids, attention_mask)\n",
    "            preds = output.argmax(dim=1)\n",
    "            acc = (preds == labels).sum().item()\n",
    "            total_acc_test += acc\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())      \n",
    "        \n",
    "    macro_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
    "    micro_f1 = f1_score(all_labels, all_preds, average=\"micro\")\n",
    "    \n",
    "    print(f\"Accuracy Score: {total_acc_test / len(test_data): .3f}\")\n",
    "    print(f\"Macro F1-score: {macro_f1: .3f}\")\n",
    "    print(f\"Micro F1-score: {micro_f1: .3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 72/72 [00:10<00:00,  7.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.974\n",
      "Macro F1-score:  0.941\n",
      "Micro F1-score:  0.974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(model, df_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
